{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10f787d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "405c4510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.1.4\n",
      "NumPy version: 1.26.2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ba5f92",
   "metadata": {},
   "source": [
    "## Load Orders Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "630a5112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f7a89ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct path - note the space and (29) in folder name\n",
    "data_path = \"../data/raw/archive (29)/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3728feb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Found 9 CSV files:\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      " 1. olist_customers_dataset.csv                            8.62 MB\n",
      " 2. olist_geolocation_dataset.csv                         58.44 MB\n",
      " 3. olist_order_items_dataset.csv                         14.72 MB\n",
      " 4. olist_order_payments_dataset.csv                       5.51 MB\n",
      " 5. olist_order_reviews_dataset.csv                       13.78 MB\n",
      " 6. olist_orders_dataset.csv                              16.84 MB\n",
      " 7. olist_products_dataset.csv                             2.27 MB\n",
      " 8. olist_sellers_dataset.csv                              0.17 MB\n",
      " 9. product_category_name_translation.csv                  0.00 MB\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(data_path):\n",
    "    files = [f for f in os.listdir(data_path) if f.endswith('.csv')]\n",
    "    \n",
    "    if files:\n",
    "        print(f\" Found {len(files)} CSV files:\\n\")\n",
    "        print(\"-\" * 80)\n",
    "        for i, file in enumerate(sorted(files), 1):\n",
    "            file_path = os.path.join(data_path, file)\n",
    "            file_size = os.path.getsize(file_path) / (1024 * 1024)  # Convert to MB\n",
    "            print(f\"{i:2d}. {file:50s} {file_size:>8.2f} MB\")\n",
    "        print(\"-\" * 80)\n",
    "    else:\n",
    "        print(\" No CSV files found in the archive folder.\")\n",
    "else:\n",
    "    print(f\" Path not found: {data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d614e3",
   "metadata": {},
   "source": [
    "## Load the Main Orders Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d7e2e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Orders Dataset\n",
    "data_path = \"../data/raw/archive (29)/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "580e85e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders Dataset Loaded Successfully!\n",
      "Total Orders: 99,441\n",
      "Columns: 8\n",
      "\n",
      "Dataset Shape: (99441, 8)\n"
     ]
    }
   ],
   "source": [
    "# Load orders\n",
    "orders = pd.read_csv(data_path + \"olist_orders_dataset.csv\")\n",
    "\n",
    "print(\"Orders Dataset Loaded Successfully!\")\n",
    "print(f\"Total Orders: {len(orders):,}\")\n",
    "print(f\"Columns: {len(orders.columns)}\")\n",
    "print(f\"\\nDataset Shape: {orders.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ec5c2c",
   "metadata": {},
   "source": [
    "## First Look at Orders Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac8b2f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names and Data Types:\n",
      "================================================================================\n",
      "order_id                         object\n",
      "customer_id                      object\n",
      "order_status                     object\n",
      "order_purchase_timestamp         object\n",
      "order_approved_at                object\n",
      "order_delivered_carrier_date     object\n",
      "order_delivered_customer_date    object\n",
      "order_estimated_delivery_date    object\n",
      "dtype: object\n",
      "\n",
      "================================================================================\n",
      "\n",
      "First 5 Rows:\n",
      "================================================================================\n",
      "                           order_id                       customer_id  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
      "\n",
      "  order_status order_purchase_timestamp    order_approved_at  \\\n",
      "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
      "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
      "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
      "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
      "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
      "\n",
      "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
      "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
      "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
      "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
      "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
      "\n",
      "  order_estimated_delivery_date  \n",
      "0           2017-10-18 00:00:00  \n",
      "1           2018-08-13 00:00:00  \n",
      "2           2018-09-04 00:00:00  \n",
      "3           2017-12-15 00:00:00  \n",
      "4           2018-02-26 00:00:00  \n"
     ]
    }
   ],
   "source": [
    "# Examine Orders Structure\n",
    "print(\"Column Names and Data Types:\")\n",
    "print(\"=\" * 80)\n",
    "print(orders.dtypes)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "print(\"=\" * 80)\n",
    "print(orders.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecf62d2",
   "metadata": {},
   "source": [
    "## Basic Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16b7f0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA QUALITY REPORT - ORDERS\n",
      "================================================================================\n",
      "\n",
      "Missing Values:\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#  Data Quality Assessment\n",
    "print(\"DATA QUALITY REPORT - ORDERS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(\"-\" * 80)\n",
    "missing = orders.isnull().sum()\n",
    "missing_pct = (orders.isnull().sum() / len(orders)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing.index,\n",
    "    'Missing_Count': missing.values,\n",
    "    'Missing_Percentage': missing_pct.values\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab8106be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Column  Missing_Count  Missing_Percentage\n",
      "order_delivered_customer_date           2965                2.98\n",
      " order_delivered_carrier_date           1783                1.79\n",
      "            order_approved_at            160                0.16\n"
     ]
    }
   ],
   "source": [
    "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "print(missing_df.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e61cf779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Duplicate Orders: 0\n",
      "\n",
      "\n",
      "Date Range:\n",
      "--------------------------------------------------------------------------------\n",
      "Earliest Order: 2016-09-04 21:15:19\n",
      "Latest Order: 2018-10-17 17:30:18\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(f\"\\n\\nDuplicate Orders: {orders.duplicated(subset=['order_id']).sum()}\")\n",
    "\n",
    "# Date range\n",
    "print(\"\\n\\nDate Range:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Earliest Order: {orders['order_purchase_timestamp'].min()}\")\n",
    "print(f\"Latest Order: {orders['order_purchase_timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d4279",
   "metadata": {},
   "source": [
    "### Key Findings\n",
    "\n",
    "- **99,441 orders** recorded from **September 2016 to October 2018** (roughly two years of data).\n",
    "- **No duplicate orders** detected — the dataset is already clean on that front.\n",
    "- **Missing delivery dates:** about **2.98%** of rows. These likely represent orders that were canceled or still processing.\n",
    "- **Date columns:** all stored as **text strings**, so they’ll need to be **converted to datetime** before any time-based analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447d2179",
   "metadata": {},
   "source": [
    "## Convert Date Columns to Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73dfaf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting date columns to datetime format...\n",
      "--------------------------------------------------------------------------------\n",
      "Converted: order_purchase_timestamp\n",
      "Converted: order_approved_at\n",
      "Converted: order_delivered_carrier_date\n",
      "Converted: order_delivered_customer_date\n",
      "Converted: order_estimated_delivery_date\n",
      "\n",
      "Verifying conversion:\n",
      "--------------------------------------------------------------------------------\n",
      "order_id                                 object\n",
      "customer_id                              object\n",
      "order_status                             object\n",
      "order_purchase_timestamp         datetime64[ns]\n",
      "order_approved_at                datetime64[ns]\n",
      "order_delivered_carrier_date     datetime64[ns]\n",
      "order_delivered_customer_date    datetime64[ns]\n",
      "order_estimated_delivery_date    datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "Date Range After Conversion:\n",
      "--------------------------------------------------------------------------------\n",
      "Earliest Order: 2016-09-04 21:15:19\n",
      "Latest Order: 2018-10-17 17:30:18\n",
      "Total Time Period: 772 days\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to proper datetime format\n",
    "print(\"Converting date columns to datetime format...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "date_columns = [\n",
    "    'order_purchase_timestamp',\n",
    "    'order_approved_at',\n",
    "    'order_delivered_carrier_date',\n",
    "    'order_delivered_customer_date',\n",
    "    'order_estimated_delivery_date'\n",
    "]\n",
    "\n",
    "for col in date_columns:\n",
    "    orders[col] = pd.to_datetime(orders[col])\n",
    "    print(f\"Converted: {col}\")\n",
    "\n",
    "print(\"\\nVerifying conversion:\")\n",
    "print(\"-\" * 80)\n",
    "print(orders.dtypes)\n",
    "\n",
    "print(\"\\nDate Range After Conversion:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Earliest Order: {orders['order_purchase_timestamp'].min()}\")\n",
    "print(f\"Latest Order: {orders['order_purchase_timestamp'].max()}\")\n",
    "print(f\"Total Time Period: {(orders['order_purchase_timestamp'].max() - orders['order_purchase_timestamp'].min()).days} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ba9deb",
   "metadata": {},
   "source": [
    "## Load Order Items Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "057ebfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order Items Dataset Loaded Successfully!\n",
      "Total Order Items: 112,650\n",
      "Columns: 7\n",
      "Dataset Shape: (112650, 7)\n",
      "\n",
      "Column Names:\n",
      "--------------------------------------------------------------------------------\n",
      "['order_id', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date', 'price', 'freight_value']\n",
      "\n",
      "First 5 Rows:\n",
      "--------------------------------------------------------------------------------\n",
      "                           order_id  order_item_id  \\\n",
      "0  00010242fe8c5a6d1ba2dd792cb16214              1   \n",
      "1  00018f77f2f0320c557190d7a144bdd3              1   \n",
      "2  000229ec398224ef6ca0657da4fc703e              1   \n",
      "3  00024acbcdf0a6daa1e931b038114c75              1   \n",
      "4  00042b26cf59d7ce69dfabb4e55b4fd9              1   \n",
      "\n",
      "                         product_id                         seller_id  \\\n",
      "0  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202   \n",
      "1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36   \n",
      "2  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d   \n",
      "3  7634da152a4610f1595efa32f14722fc  9d7a1d34a5052409006425275ba1c2b4   \n",
      "4  ac6c3623068f30de03045865e4e10089  df560393f3a51e74553ab94004ba5c87   \n",
      "\n",
      "   shipping_limit_date  price  freight_value  \n",
      "0  2017-09-19 09:45:35  58.90          13.29  \n",
      "1  2017-05-03 11:05:13 239.90          19.93  \n",
      "2  2018-01-18 14:48:30 199.00          17.87  \n",
      "3  2018-08-15 10:10:18  12.99          12.79  \n",
      "4  2017-02-13 13:57:51 199.90          18.14  \n"
     ]
    }
   ],
   "source": [
    "#  Load Order Items Dataset\n",
    "order_items = pd.read_csv(data_path + \"olist_order_items_dataset.csv\")\n",
    "\n",
    "print(\"Order Items Dataset Loaded Successfully!\")\n",
    "print(f\"Total Order Items: {len(order_items):,}\")\n",
    "print(f\"Columns: {len(order_items.columns)}\")\n",
    "print(f\"Dataset Shape: {order_items.shape}\")\n",
    "\n",
    "print(\"\\nColumn Names:\")\n",
    "print(\"-\" * 80)\n",
    "print(order_items.columns.tolist())\n",
    "\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "print(\"-\" * 80)\n",
    "print(order_items.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781630b5",
   "metadata": {},
   "source": [
    "## Load Payments Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "301266eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order Payments Dataset Loaded Successfully!\n",
      "Total Payment Records: 103,886\n",
      "Columns: 5\n",
      "Dataset Shape: (103886, 5)\n",
      "\n",
      "Column Names:\n",
      "--------------------------------------------------------------------------------\n",
      "['order_id', 'payment_sequential', 'payment_type', 'payment_installments', 'payment_value']\n",
      "\n",
      "First 5 Rows:\n",
      "--------------------------------------------------------------------------------\n",
      "                           order_id  payment_sequential payment_type  \\\n",
      "0  b81ef226f3fe1789b1e8b2acac839d17                   1  credit_card   \n",
      "1  a9810da82917af2d9aefd1278f1dcfa0                   1  credit_card   \n",
      "2  25e8ea4e93396b6fa0d3dd708e76c1bd                   1  credit_card   \n",
      "3  ba78997921bbcdc1373bb41e913ab953                   1  credit_card   \n",
      "4  42fdf880ba16b47b59251dd489d4441a                   1  credit_card   \n",
      "\n",
      "   payment_installments  payment_value  \n",
      "0                     8          99.33  \n",
      "1                     1          24.39  \n",
      "2                     1          65.71  \n",
      "3                     8         107.78  \n",
      "4                     2         128.45  \n",
      "\n",
      "Payment Types:\n",
      "--------------------------------------------------------------------------------\n",
      "payment_type\n",
      "credit_card    76795\n",
      "boleto         19784\n",
      "voucher         5775\n",
      "debit_card      1529\n",
      "not_defined        3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load Order Payments Dataset\n",
    "payments = pd.read_csv(data_path + \"olist_order_payments_dataset.csv\")\n",
    "\n",
    "print(\"Order Payments Dataset Loaded Successfully!\")\n",
    "print(f\"Total Payment Records: {len(payments):,}\")\n",
    "print(f\"Columns: {len(payments.columns)}\")\n",
    "print(f\"Dataset Shape: {payments.shape}\")\n",
    "\n",
    "print(\"\\nColumn Names:\")\n",
    "print(\"-\" * 80)\n",
    "print(payments.columns.tolist())\n",
    "\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "print(\"-\" * 80)\n",
    "print(payments.head())\n",
    "\n",
    "print(\"\\nPayment Types:\")\n",
    "print(\"-\" * 80)\n",
    "print(payments['payment_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711bfe1",
   "metadata": {},
   "source": [
    "## Load Products and Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "008fcb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRODUCTS DATASET\n",
      "================================================================================\n",
      "Total Products: 32,951\n",
      "Columns: ['product_id', 'product_category_name', 'product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']\n",
      "\n",
      "First 3 Rows:\n",
      "                         product_id product_category_name  \\\n",
      "0  1e9e8ef04dbcff4541ed26657ea517e5            perfumaria   \n",
      "1  3aa071139cb16b67ca9e5dea641aaa2f                 artes   \n",
      "2  96bd76ec8810374ed1b65e291975717f         esporte_lazer   \n",
      "\n",
      "   product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
      "0                40.00                      287.00                1.00   \n",
      "1                44.00                      276.00                1.00   \n",
      "2                46.00                      250.00                1.00   \n",
      "\n",
      "   product_weight_g  product_length_cm  product_height_cm  product_width_cm  \n",
      "0            225.00              16.00              10.00             14.00  \n",
      "1           1000.00              30.00              18.00             20.00  \n",
      "2            154.00              18.00               9.00             15.00  \n",
      "\n",
      "\n",
      "CUSTOMERS DATASET\n",
      "================================================================================\n",
      "Total Customers: 99,441\n",
      "Columns: ['customer_id', 'customer_unique_id', 'customer_zip_code_prefix', 'customer_city', 'customer_state']\n",
      "\n",
      "First 3 Rows:\n",
      "                        customer_id                customer_unique_id  \\\n",
      "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
      "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
      "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
      "\n",
      "   customer_zip_code_prefix          customer_city customer_state  \n",
      "0                     14409                 franca             SP  \n",
      "1                      9790  sao bernardo do campo             SP  \n",
      "2                      1151              sao paulo             SP  \n"
     ]
    }
   ],
   "source": [
    "#  Load Products and Customers Datasets\n",
    "products = pd.read_csv(data_path + \"olist_products_dataset.csv\")\n",
    "customers = pd.read_csv(data_path + \"olist_customers_dataset.csv\")\n",
    "\n",
    "print(\"PRODUCTS DATASET\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total Products: {len(products):,}\")\n",
    "print(f\"Columns: {products.columns.tolist()}\")\n",
    "print(\"\\nFirst 3 Rows:\")\n",
    "print(products.head(3))\n",
    "\n",
    "print(\"\\n\\nCUSTOMERS DATASET\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total Customers: {len(customers):,}\")\n",
    "print(f\"Columns: {customers.columns.tolist()}\")\n",
    "print(\"\\nFirst 3 Rows:\")\n",
    "print(customers.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60e8936",
   "metadata": {},
   "source": [
    "### Data Summary\n",
    "\n",
    "- **Orders:** 99,441 (covers roughly 2 years)\n",
    "- **Order Items:** 112,650 (many orders contain multiple items)\n",
    "- **Payment Records:** 103,886\n",
    "- **Products:** 32,951 unique products\n",
    "- **Customers:** 99,441 unique customers\n",
    "- **Payment Methods:**\n",
    "  - Credit card: **74%**\n",
    "  - Boleto: **19%**\n",
    "  - Voucher: **6%**\n",
    "  - Debit card: **1%**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90131e98",
   "metadata": {},
   "source": [
    "## Understanding Dataset Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f0930a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Orders in main table: 99,441\n",
      "Orders with items: 98,666\n",
      "Match: False\n"
     ]
    }
   ],
   "source": [
    "# Check if all orders have items\n",
    "orders_with_items = order_items['order_id'].nunique()\n",
    "print(f\"\\nOrders in main table: {len(orders):,}\")\n",
    "print(f\"Orders with items: {orders_with_items:,}\")\n",
    "print(f\"Match: {orders_with_items == len(orders)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Orders with payments: 99,440\n",
      "Coverage: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Check payment coverage\n",
    "orders_with_payments = payments['order_id'].nunique()\n",
    "print(f\"\\nOrders with payments: {orders_with_payments:,}\")\n",
    "print(f\"Coverage: {(orders_with_payments/len(orders)*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03256357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique customers in orders: 99,441\n",
      "Customers in customer table: 99,441\n"
     ]
    }
   ],
   "source": [
    "# Check customer coverage\n",
    "orders_with_customers = orders['customer_id'].nunique()\n",
    "print(f\"\\nUnique customers in orders: {orders_with_customers:,}\")\n",
    "print(f\"Customers in customer table: {len(customers):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e14d5492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average items per order: 1.13\n",
      "\n",
      "Orders with multiple payment methods: 2,961\n"
     ]
    }
   ],
   "source": [
    "# Average items per order\n",
    "avg_items = len(order_items) / len(orders)\n",
    "print(f\"\\nAverage items per order: {avg_items:.2f}\")\n",
    "\n",
    "# Check for multiple payments per order\n",
    "orders_multi_payment = payments.groupby('order_id').size()\n",
    "print(f\"\\nOrders with multiple payment methods: {(orders_multi_payment > 1).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefe11fd",
   "metadata": {},
   "source": [
    "## Create Master Dataset (Merge All Tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Starting with orders: 99,441 rows\n"
     ]
    }
   ],
   "source": [
    "# Start with orders\n",
    "master = orders.copy()\n",
    "print(f\"Step 1: Starting with orders: {len(master):,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9dbb4831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: After merging order items: 113,425 rows\n"
     ]
    }
   ],
   "source": [
    "# Merge with order items\n",
    "master = master.merge(order_items, on='order_id', how='left')\n",
    "print(f\"Step 2: After merging order items: {len(master):,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac8a5330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: After merging products: 113,425 rows\n",
      "Step 4: After merging customers: 113,425 rows\n"
     ]
    }
   ],
   "source": [
    "# Merge with products\n",
    "master = master.merge(products, on='product_id', how='left')\n",
    "print(f\"Step 3: After merging products: {len(master):,} rows\")\n",
    "\n",
    "# Merge with customers\n",
    "master = master.merge(customers, on='customer_id', how='left')\n",
    "print(f\"Step 4: After merging customers: {len(master):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aeb3f74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: After merging payments: 113,425 rows\n",
      "\n",
      "Master dataset created successfully!\n",
      "Final shape: (113425, 29)\n",
      "Total columns: 29\n"
     ]
    }
   ],
   "source": [
    "# For payments, we need to aggregate first (some orders have multiple payments)\n",
    "payments_agg = payments.groupby('order_id').agg({\n",
    "    'payment_type': 'first',\n",
    "    'payment_value': 'sum',\n",
    "    'payment_installments': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "master = master.merge(payments_agg, on='order_id', how='left')\n",
    "print(f\"Step 5: After merging payments: {len(master):,} rows\")\n",
    "\n",
    "print(\"\\nMaster dataset created successfully!\")\n",
    "print(f\"Final shape: {master.shape}\")\n",
    "print(f\"Total columns: {len(master.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872eb7a",
   "metadata": {},
   "source": [
    "## Calculate Key Business Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65597143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total order value (price + freight)\n",
    "master['total_order_value'] = master['price'] + master['freight_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9c7cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delivery time in days\n",
    "master['delivery_time_days'] = (\n",
    "    master['order_delivered_customer_date'] - master['order_purchase_timestamp']\n",
    ").dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "102313c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected delivery time\n",
    "master['expected_delivery_days'] = (\n",
    "    master['order_estimated_delivery_date'] - master['order_purchase_timestamp']\n",
    ").dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e2a15e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Was delivery late?\n",
    "master['delivery_late'] = master['delivery_time_days'] > master['expected_delivery_days']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71e79bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time components\n",
    "master['order_year'] = master['order_purchase_timestamp'].dt.year\n",
    "master['order_month'] = master['order_purchase_timestamp'].dt.month\n",
    "master['order_month_name'] = master['order_purchase_timestamp'].dt.strftime('%Y-%m')\n",
    "master['order_day_of_week'] = master['order_purchase_timestamp'].dt.day_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ee212cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated columns added successfully!\n",
      "\n",
      "New columns:\n",
      "--------------------------------------------------------------------------------\n",
      "  - total_order_value\n",
      "  - delivery_time_days\n",
      "  - expected_delivery_days\n",
      "  - delivery_late\n",
      "  - order_year\n",
      "  - order_month\n",
      "  - order_month_name\n",
      "  - order_day_of_week\n",
      "\n",
      "Sample of calculated metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "                           order_id  price  freight_value  total_order_value  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7  29.99           8.72              38.71   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451 118.70          22.76             141.46   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d 159.90          19.22             179.12   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a  45.00          27.20              72.20   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159  19.90           8.72              28.62   \n",
      "\n",
      "   delivery_time_days  delivery_late  \n",
      "0                8.00          False  \n",
      "1               13.00          False  \n",
      "2                9.00          False  \n",
      "3               13.00          False  \n",
      "4                2.00          False  \n"
     ]
    }
   ],
   "source": [
    "print(\"Calculated columns added successfully!\")\n",
    "print(\"\\nNew columns:\")\n",
    "print(\"-\" * 80)\n",
    "new_cols = ['total_order_value', 'delivery_time_days', 'expected_delivery_days', \n",
    "            'delivery_late', 'order_year', 'order_month', 'order_month_name', 'order_day_of_week']\n",
    "for col in new_cols:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(\"\\nSample of calculated metrics:\")\n",
    "print(\"-\" * 80)\n",
    "print(master[['order_id', 'price', 'freight_value', 'total_order_value', \n",
    "              'delivery_time_days', 'delivery_late']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab0a25",
   "metadata": {},
   "source": [
    "## Save the Master Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dea8353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master dataset saved to: ../data/processed/master_sales_data.csv\n",
      "File size: 124.97 MB in memory\n"
     ]
    }
   ],
   "source": [
    "output_path = \"../data/processed/\"\n",
    "\n",
    "# Save master dataset\n",
    "master.to_csv(output_path + \"master_sales_data.csv\", index=False)\n",
    "print(f\"Master dataset saved to: {output_path}master_sales_data.csv\")\n",
    "print(f\"File size: {master.memory_usage(deep=True).sum() / (1024**2):.2f} MB in memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf82c978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Master Dataset Summary:\n",
      "================================================================================\n",
      "Total rows: 113,425\n",
      "Total columns: 37\n",
      "Date range: 2016-09-04 21:15:19 to 2018-10-17 17:30:18\n",
      "Total revenue: $15,843,553.24\n"
     ]
    }
   ],
   "source": [
    "# Quick summary\n",
    "print(\"\\nMaster Dataset Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total rows: {len(master):,}\")\n",
    "print(f\"Total columns: {len(master.columns)}\")\n",
    "print(f\"Date range: {master['order_purchase_timestamp'].min()} to {master['order_purchase_timestamp'].max()}\")\n",
    "print(f\"Total revenue: ${master['total_order_value'].sum():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7578534",
   "metadata": {},
   "source": [
    "### Important Observations\n",
    "\n",
    "- **Total Revenue:** \\$15.8 million over the 2-year period.\n",
    "- **Order Items:** 113,425 (many orders include multiple products).\n",
    "- **Orders Without Items:** 775 (likely canceled or invalid orders).\n",
    "- **Multiple Payment Methods:** 2,961 orders used more than one payment method.\n",
    "- **Average Items per Order:** 1.13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8aad3112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAY 1 - DATA LOADING AND PREPARATION - COMPLETE\n",
      "================================================================================\n",
      "\n",
      "What we accomplished:\n",
      "--------------------------------------------------------------------------------\n",
      "1. Loaded 9 CSV files from Brazilian e-commerce dataset\n",
      "2. Converted date columns to proper datetime format\n",
      "3. Merged all datasets into master analysis table\n",
      "4. Added calculated business metrics\n",
      "5. Saved processed data for analysis\n",
      "\n",
      "Key Statistics:\n",
      "--------------------------------------------------------------------------------\n",
      "Total Orders: 99,441\n",
      "Total Order Items: 113,425\n",
      "Total Revenue: $15,843,553.24\n",
      "Date Range: 2016 - 2018\n",
      "Unique Customers: 99,441\n",
      "Unique Products: 32,951\n",
      "States Covered: 27\n",
      "\n",
      "Next Steps (Day 2):\n",
      "--------------------------------------------------------------------------------\n",
      "1. Revenue analysis by time period\n",
      "2. Customer behavior analysis\n",
      "3. Product category performance\n",
      "4. Delivery performance metrics\n",
      "5. Create visualizations\n",
      "\n",
      "Files created:\n",
      "--------------------------------------------------------------------------------\n",
      "- notebooks/01_data_exploration.ipynb\n",
      "- data/processed/master_sales_data.csv\n"
     ]
    }
   ],
   "source": [
    "#Summary\n",
    "print(\"DAY 1 - DATA LOADING AND PREPARATION - COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nWhat we accomplished:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"1. Loaded 9 CSV files from Brazilian e-commerce dataset\")\n",
    "print(\"2. Converted date columns to proper datetime format\")\n",
    "print(\"3. Merged all datasets into master analysis table\")\n",
    "print(\"4. Added calculated business metrics\")\n",
    "print(\"5. Saved processed data for analysis\")\n",
    "\n",
    "print(\"\\nKey Statistics:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total Orders: {len(orders):,}\")\n",
    "print(f\"Total Order Items: {len(master):,}\")\n",
    "print(f\"Total Revenue: ${master['total_order_value'].sum():,.2f}\")\n",
    "print(f\"Date Range: {master['order_year'].min()} - {master['order_year'].max()}\")\n",
    "print(f\"Unique Customers: {master['customer_id'].nunique():,}\")\n",
    "print(f\"Unique Products: {master['product_id'].nunique():,}\")\n",
    "print(f\"States Covered: {master['customer_state'].nunique()}\")\n",
    "\n",
    "print(\"\\nNext Steps (Day 2):\")\n",
    "print(\"-\" * 80)\n",
    "print(\"1. Revenue analysis by time period\")\n",
    "print(\"2. Customer behavior analysis\")\n",
    "print(\"3. Product category performance\")\n",
    "print(\"4. Delivery performance metrics\")\n",
    "print(\"5. Create visualizations\")\n",
    "\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"- notebooks/01_data_exploration.ipynb\")\n",
    "print(\"- data/processed/master_sales_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
